#!/usr/bin/env python3
"""
Complete MySQL Migration Script - FINAL VERSION
Consolidates all WMS modules and schema into one comprehensive migration
This is the ONLY MySQL migration file you need - all others are duplicates

Features included:
- User Management with roles and permissions
- GRPO (Goods Receipt Purchase Order) 
- Inventory Transfer with warehouse support
- Pick List Management with SAP B1 integration
- Inventory Counting
- Bin Scanning with barcode support
- QR Code Label printing
- Quality Control Dashboard
- Branch Management
- Complete SAP B1 integration schemas
- Batch Serial Number Validation (Performance Optimized for 1000+ serials)
- PostgreSQL compatibility for Replit environment

Run: python mysql_complete_migration_final.py
"""

import os
import sys
import json
import logging
import pymysql
from pymysql.cursors import DictCursor
from werkzeug.security import generate_password_hash
from datetime import datetime

# Load configuration from JSON file
config = {}
config_paths = [
    'sap_login/credential.json',  # Primary credential path
    'config.json',                # Fallback to old path
]

config_loaded = False
for config_path in config_paths:
    try:
        with open(config_path, 'r') as f:
            config = json.load(f)
        print(f"‚úÖ Configuration loaded from {config_path}")
        config_loaded = True
        break
    except FileNotFoundError:
        continue
    except Exception as e:
        print(f"‚ö†Ô∏è Could not load {config_path}: {e}")

if not config_loaded:
    print("‚ö†Ô∏è No JSON configuration file found, using environment variables as fallback")

def get_config(key, default=None):
    """Get configuration value from JSON config first, then environment variables as fallback"""
    return config.get(key, os.environ.get(key, default))

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class CompleteMySQLMigrationFinal:
    def __init__(self):
        self.connection = None
        
    def get_mysql_config(self):
        """Get MySQL configuration from JSON config, then environment, then interactive input"""
        print("=== MySQL Configuration ===")
        config_dict = {
            'host': get_config('MYSQL_HOST') or input("MySQL Host (localhost): ").strip() or 'localhost',
            'port': int(get_config('MYSQL_PORT') or input("MySQL Port (3306): ").strip() or '3306'),
            'user': get_config('MYSQL_USER') or input("MySQL Username: ").strip(),
            'password': get_config('MYSQL_PASSWORD') or input("MySQL Password: ").strip(),
            'database': get_config('MYSQL_DATABASE') or input("Database Name (wms_db_dev): ").strip() or 'wms_db_dev',
            'charset': 'utf8mb4',
            'autocommit': False
        }
        return config_dict
    
    def connect(self, config):
        """Connect to MySQL database"""
        try:
            self.connection = pymysql.connect(
                host=config['host'],
                port=config['port'], 
                user=config['user'],
                password=config['password'],
                database=config['database'],
                charset=config['charset'],
                cursorclass=DictCursor,
                autocommit=config['autocommit']
            )
            logger.info(f"‚úÖ Connected to MySQL: {config['database']} at {config['host']}:{config['port']}")
            return True
        except Exception as e:
            logger.error(f"‚ùå MySQL connection failed: {e}")
            return False
    
    def execute_query(self, query, params=None):
        """Execute query with error handling"""
        try:
            with self.connection.cursor() as cursor:
                cursor.execute(query, params)
                return cursor.fetchall()
        except Exception as e:
            logger.error(f"‚ùå Query failed: {e}")
            logger.error(f"Query: {query[:100]}...")
            raise
    
    def table_exists(self, table_name):
        """Check if table exists"""
        query = """
        SELECT COUNT(*) as count 
        FROM information_schema.tables 
        WHERE table_schema = DATABASE() AND table_name = %s
        """
        result = self.execute_query(query, [table_name])
        return result[0]['count'] > 0
    
    def column_exists(self, table_name, column_name):
        """Check if column exists in table"""
        query = """
        SELECT COUNT(*) as count 
        FROM information_schema.columns 
        WHERE table_schema = DATABASE() AND table_name = %s AND column_name = %s
        """
        result = self.execute_query(query, [table_name, column_name])
        return result[0]['count'] > 0
    
    def create_env_file(self, config):
        """Create comprehensive .env file"""
        env_content = f"""# WMS Complete Environment Configuration
# Generated by mysql_complete_migration_final.py on {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

# =================================
# DATABASE CONFIGURATION
# =================================
# Primary MySQL Database
DATABASE_URL=mysql+pymysql://{config['user']}:{config['password']}@{config['host']}:{config['port']}/{config['database']}

# MySQL Direct Connection Settings
MYSQL_HOST={config['host']}
MYSQL_PORT={config['port']}
MYSQL_USER={config['user']}
MYSQL_PASSWORD={config['password']}
MYSQL_DATABASE={config['database']}

# PostgreSQL (Replit Cloud Fallback) - Auto-configured by Replit
# DATABASE_URL will be overridden by Replit in cloud environment

# =================================
# APPLICATION SECURITY
# =================================
# Session Secret (CHANGE IN PRODUCTION!)
SESSION_SECRET=WMS-Secret-Key-{datetime.now().strftime('%Y%m%d')}-Change-In-Production

# Flask Configuration
FLASK_ENV=development
FLASK_DEBUG=True

# =================================
# SAP BUSINESS ONE INTEGRATION
# =================================
# SAP B1 Server Configuration
SAP_B1_SERVER=https://192.168.1.5:50000
SAP_B1_USERNAME=manager
SAP_B1_PASSWORD=1422
SAP_B1_COMPANY_DB=EINV-TESTDB-LIVE-HUST

# SAP B1 Connection Timeout (seconds)
SAP_B1_TIMEOUT=30
SAP_B1_VERIFY_SSL=false

# =================================
# WAREHOUSE MANAGEMENT SETTINGS
# =================================
# Default warehouse codes
DEFAULT_WAREHOUSE=01
DEFAULT_BIN_LOCATION=01-A01-001

# Barcode/QR Code Settings
BARCODE_FORMAT=CODE128
QR_CODE_SIZE=10
LABEL_PRINTER_IP=192.168.1.100

# =================================
# EMAIL CONFIGURATION (Optional)
# =================================
MAIL_SERVER=smtp.gmail.com
MAIL_PORT=587
MAIL_USE_TLS=true
MAIL_USERNAME=your-email@company.com
MAIL_PASSWORD=your-app-password

# =================================
# LOGGING CONFIGURATION
# =================================
LOG_LEVEL=INFO
LOG_FILE=logs/wms.log

# =================================
# BACKUP CONFIGURATION
# =================================
BACKUP_RETENTION_DAYS=30
AUTO_BACKUP_ENABLED=true
BACKUP_PATH=backups/
"""
        
        try:
            with open('.env', 'w') as f:
                f.write(env_content)
            logger.info("‚úÖ Created comprehensive .env file")
            return True
        except Exception as e:
            logger.error(f"‚ùå Failed to create .env file: {e}")
            return False
    
    def add_missing_columns(self):
        """Add any missing columns to existing tables"""
        logger.info("Checking for missing columns in existing tables...")
        
        # Check branches table columns
        if self.table_exists('branches'):
            missing_columns = []
            branch_columns = [
                ('name', 'VARCHAR(100)'),
                ('description', 'VARCHAR(255)'),
                ('branch_code', 'VARCHAR(10) UNIQUE'),
                ('branch_name', 'VARCHAR(100)'),
                ('city', 'VARCHAR(50)'),
                ('state', 'VARCHAR(50)'),
                ('postal_code', 'VARCHAR(20)'),
                ('country', 'VARCHAR(50)'),
                ('warehouse_codes', 'TEXT'),
                ('is_default', 'BOOLEAN DEFAULT FALSE'),
                ('active', 'BOOLEAN DEFAULT TRUE')  # Required by application code
            ]
            
            for col_name, col_def in branch_columns:
                if not self.column_exists('branches', col_name):
                    missing_columns.append((col_name, col_def))
            
            for col_name, col_def in missing_columns:
                try:
                    self.execute_query(f"ALTER TABLE branches ADD COLUMN {col_name} {col_def}")
                    logger.info(f"‚úÖ Added missing column: branches.{col_name}")
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è Could not add column branches.{col_name}: {e}")
        
        # Check users table columns - CRITICAL: Add missing 'active' column
        if self.table_exists('users'):
            missing_user_columns = []
            user_columns = [
                ('active', 'BOOLEAN DEFAULT TRUE'),  # Required by application code
                ('first_name', 'VARCHAR(80)'),
                ('last_name', 'VARCHAR(80)'),
                ('branch_id', 'VARCHAR(10)'),
                ('branch_name', 'VARCHAR(100)'),
                ('default_branch_id', 'VARCHAR(10)'),
                ('must_change_password', 'BOOLEAN DEFAULT FALSE'),
                ('last_login', 'DATETIME'),
                ('permissions', 'TEXT'),
                ('created_at', 'DATETIME DEFAULT CURRENT_TIMESTAMP'),
                ('updated_at', 'DATETIME DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP')
            ]
            
            for col_name, col_def in user_columns:
                if not self.column_exists('users', col_name):
                    missing_user_columns.append((col_name, col_def))
            
            for col_name, col_def in missing_user_columns:
                try:
                    self.execute_query(f"ALTER TABLE users ADD COLUMN {col_name} {col_def}")
                    logger.info(f"‚úÖ Added missing column: users.{col_name}")
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è Could not add column users.{col_name}: {e}")
        
        # Check pick_lists table columns for SAP B1 compatibility
        if self.table_exists('pick_lists'):
            pick_list_columns = [
                ('absolute_entry', 'INT'),
                ('name', 'VARCHAR(100)'),
                ('owner_code', 'INT'),
                ('owner_name', 'VARCHAR(100)'),
                ('pick_date', 'DATE'),
                ('status', 'VARCHAR(20) DEFAULT "pending"'),
                ('object_type', 'VARCHAR(10) DEFAULT "156"'),
                ('use_base_units', 'VARCHAR(5) DEFAULT "tNO"'),
                ('priority', 'VARCHAR(20) DEFAULT "normal"'),
                ('warehouse_code', 'VARCHAR(10)'),
                ('customer_code', 'VARCHAR(50)'),
                ('customer_name', 'VARCHAR(100)'),
                ('total_items', 'INT DEFAULT 0'),
                ('picked_items', 'INT DEFAULT 0'),
                ('notes', 'TEXT'),
                ('remarks', 'TEXT')
            ]
            
            for col_name, col_def in pick_list_columns:
                if not self.column_exists('pick_lists', col_name):
                    try:
                        self.execute_query(f"ALTER TABLE pick_lists ADD COLUMN {col_name} {col_def}")
                        logger.info(f"‚úÖ Added missing column: pick_lists.{col_name}")
                    except Exception as e:
                        logger.warning(f"‚ö†Ô∏è Could not add column pick_lists.{col_name}: {e}")
        
        # CRITICAL: Check QR Code Labels table for missing columns
        if self.table_exists('qr_code_labels'):
            logger.info("üîç Checking QR code labels table for missing columns...")
            
            # Handle legacy fields that exist in MySQL but not in current models
            legacy_fields = [
                ('label_number', 'VARCHAR(50)', 'NULL'),
                ('qr_code_data', 'TEXT', 'NULL'),  # This is causing the current error
            ]
            
            for field_name, field_type, default_value in legacy_fields:
                try:
                    if self.column_exists('qr_code_labels', field_name):
                        logger.info(f"‚ö†Ô∏è Found existing {field_name} column, fixing to allow NULL...")
                        # Make the field nullable with default
                        self.execute_query(f"ALTER TABLE qr_code_labels MODIFY COLUMN {field_name} {field_type} DEFAULT {default_value}")
                        logger.info(f"‚úÖ Fixed {field_name} column to be nullable with default")
                    else:
                        # Add the field if it doesn't exist (for compatibility)
                        self.execute_query(f"ALTER TABLE qr_code_labels ADD COLUMN {field_name} {field_type} DEFAULT {default_value}")
                        logger.info(f"‚úÖ Added {field_name} column for backward compatibility")
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è Could not fix {field_name} column: {e}")
                    # If all else fails, try to just make it nullable
                    try:
                        self.execute_query(f"ALTER TABLE qr_code_labels MODIFY COLUMN {field_name} {field_type}")
                        logger.info(f"‚úÖ Made {field_name} column nullable")
                    except Exception as e2:
                        logger.error(f"‚ùå Could not fix {field_name} column at all: {e2}")
            
            qr_code_columns = [
                ('item_name', 'VARCHAR(200)'),
                ('po_number', 'VARCHAR(100)'),
                ('bin_code', 'VARCHAR(100)'),
                ('grpo_item_id', 'INT'),
                ('inventory_transfer_item_id', 'INT'),
                ('qr_content', 'TEXT'),
                ('qr_format', 'VARCHAR(20) DEFAULT "TEXT"'),
                ('label_type', 'VARCHAR(50)'),
                ('quantity', 'DECIMAL(15,4)'),
                ('uom', 'VARCHAR(20)'),
                ('warehouse_code', 'VARCHAR(50)'),
                ('batch_number', 'VARCHAR(100)'),
                ('expiry_date', 'DATE'),
                ('user_id', 'INT'),
                ('created_at', 'DATETIME DEFAULT CURRENT_TIMESTAMP'),
                ('updated_at', 'DATETIME DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP')
            ]
            
            for col_name, col_def in qr_code_columns:
                if not self.column_exists('qr_code_labels', col_name):
                    try:
                        self.execute_query(f"ALTER TABLE qr_code_labels ADD COLUMN {col_name} {col_def}")
                        logger.info(f"‚úÖ Added missing column: qr_code_labels.{col_name} - CRITICAL FOR QR CODE GENERATION")
                    except Exception as e:
                        logger.warning(f"‚ö†Ô∏è Could not add column qr_code_labels.{col_name}: {e}")
        
        # Check bin_items table for missing columns
        if self.table_exists('bin_items'):
            bin_item_columns = [
                ('item_name', 'VARCHAR(255)'),
                ('batch_attribute1', 'VARCHAR(100)'),
                ('batch_attribute2', 'VARCHAR(100)'),
                ('batch_status', 'VARCHAR(50) DEFAULT "bdsStatus_Released"'),
            ]
            
            for col_name, col_def in bin_item_columns:
                if not self.column_exists('bin_items', col_name):
                    try:
                        self.execute_query(f"ALTER TABLE bin_items ADD COLUMN {col_name} {col_def}")
                        logger.info(f"‚úÖ Added missing column: bin_items.{col_name}")
                    except Exception as e:
                        logger.warning(f"‚ö†Ô∏è Could not add column bin_items.{col_name}: {e}")

        # Check sales_orders table for missing columns (for picklist integration)
        if self.table_exists('sales_orders'):
            sales_order_columns = [
                ('doc_entry', 'INT UNIQUE NOT NULL'),
                ('doc_num', 'INT'),
                ('doc_type', 'VARCHAR(50)'),
                ('doc_date', 'DATETIME'),
                ('doc_due_date', 'DATETIME'),
                ('card_code', 'VARCHAR(50)'),
                ('card_name', 'VARCHAR(200)'),
                ('address', 'TEXT'),
                ('doc_total', 'DECIMAL(15,2)'),
                ('doc_currency', 'VARCHAR(10)'),
                ('comments', 'TEXT'),
                ('document_status', 'VARCHAR(50)'),
                ('last_sap_sync', 'DATETIME DEFAULT CURRENT_TIMESTAMP')
            ]
            
            for col_name, col_def in sales_order_columns:
                if not self.column_exists('sales_orders', col_name):
                    try:
                        if 'UNIQUE' in col_def:
                            # Handle unique constraint separately for existing tables
                            base_def = col_def.replace(' UNIQUE', '').replace(' NOT NULL', '')
                            self.execute_query(f"ALTER TABLE sales_orders ADD COLUMN {col_name} {base_def}")
                            logger.info(f"‚úÖ Added missing column: sales_orders.{col_name}")
                        else:
                            self.execute_query(f"ALTER TABLE sales_orders ADD COLUMN {col_name} {col_def}")
                            logger.info(f"‚úÖ Added missing column: sales_orders.{col_name}")
                    except Exception as e:
                        logger.warning(f"‚ö†Ô∏è Could not add column sales_orders.{col_name}: {e}")

        # Check sales_order_lines table for missing columns
        if self.table_exists('sales_order_lines'):
            sales_order_line_columns = [
                ('sales_order_id', 'INT NOT NULL'),
                ('line_num', 'INT NOT NULL'),
                ('item_code', 'VARCHAR(100)'),
                ('item_description', 'VARCHAR(255)'),
                ('quantity', 'DECIMAL(15,3)'),
                ('open_quantity', 'DECIMAL(15,3)'),
                ('delivered_quantity', 'DECIMAL(15,3)'),
                ('unit_price', 'DECIMAL(15,4)'),
                ('line_total', 'DECIMAL(15,2)'),
                ('warehouse_code', 'VARCHAR(50)'),
                ('unit_of_measure', 'VARCHAR(20)'),
                ('line_status', 'VARCHAR(50)')
            ]
            
            for col_name, col_def in sales_order_line_columns:
                if not self.column_exists('sales_order_lines', col_name):
                    try:
                        self.execute_query(f"ALTER TABLE sales_order_lines ADD COLUMN {col_name} {col_def}")
                        logger.info(f"‚úÖ Added missing column: sales_order_lines.{col_name}")
                    except Exception as e:
                        logger.warning(f"‚ö†Ô∏è Could not add column sales_order_lines.{col_name}: {e}")

        # Check inventory_transfers table for SAP B1 integration enhancements
        if self.table_exists('inventory_transfers'):
            inventory_transfer_columns = [
                ('transfer_request_number', 'VARCHAR(20) NOT NULL'),
                ('sap_document_number', 'VARCHAR(20)'),
                ('status', 'VARCHAR(20) DEFAULT "draft"'),
                ('user_id', 'INT NOT NULL'),
                ('qc_approver_id', 'INT'),
                ('qc_approved_at', 'DATETIME'),
                ('qc_notes', 'TEXT'),
                ('from_warehouse', 'VARCHAR(20)'),
                ('to_warehouse', 'VARCHAR(20)'),
                ('created_at', 'DATETIME DEFAULT CURRENT_TIMESTAMP'),
                ('updated_at', 'DATETIME DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP')
            ]
            
            for col_name, col_def in inventory_transfer_columns:
                if not self.column_exists('inventory_transfers', col_name):
                    try:
                        self.execute_query(f"ALTER TABLE inventory_transfers ADD COLUMN {col_name} {col_def}")
                        logger.info(f"‚úÖ Added missing column: inventory_transfers.{col_name}")
                    except Exception as e:
                        logger.warning(f"‚ö†Ô∏è Could not add column inventory_transfers.{col_name}: {e}")

        # Check inventory_transfer_items table for warehouse mapping improvements
        if self.table_exists('inventory_transfer_items'):
            inventory_transfer_item_columns = [
                ('inventory_transfer_id', 'INT NOT NULL'),
                ('item_code', 'VARCHAR(50) NOT NULL'),
                ('item_name', 'VARCHAR(200) NOT NULL'),
                ('quantity', 'DECIMAL(15,3) NOT NULL'),
                ('requested_quantity', 'DECIMAL(15,3) NOT NULL'),
                ('transferred_quantity', 'DECIMAL(15,3) DEFAULT 0'),
                ('remaining_quantity', 'DECIMAL(15,3) NOT NULL'),
                ('unit_of_measure', 'VARCHAR(10) NOT NULL'),
                ('from_bin', 'VARCHAR(20)'),
                ('to_bin', 'VARCHAR(20)'),
                ('from_bin_location', 'VARCHAR(50)'),
                ('to_bin_location', 'VARCHAR(50)'),
                ('batch_number', 'VARCHAR(50)'),
                ('available_batches', 'TEXT'),
                ('qc_status', 'VARCHAR(20) DEFAULT "pending"'),
                ('qc_notes', 'TEXT'),
                ('created_at', 'DATETIME DEFAULT CURRENT_TIMESTAMP')
            ]
            
            for col_name, col_def in inventory_transfer_item_columns:
                if not self.column_exists('inventory_transfer_items', col_name):
                    try:
                        self.execute_query(f"ALTER TABLE inventory_transfer_items ADD COLUMN {col_name} {col_def}")
                        logger.info(f"‚úÖ Added missing column: inventory_transfer_items.{col_name}")
                    except Exception as e:
                        logger.warning(f"‚ö†Ô∏è Could not add column inventory_transfer_items.{col_name}: {e}")

        # Check and add missing columns for serial_number_transfer_items table
        if self.table_exists('serial_number_transfer_items'):
            logger.info("Checking serial_number_transfer_items table for missing columns...")
            
            serial_transfer_item_columns = [
                ('quantity', 'INT NOT NULL DEFAULT 1'),
            ]
            
            for col_name, col_def in serial_transfer_item_columns:
                if not self.column_exists('serial_number_transfer_items', col_name):
                    try:
                        self.execute_query(f"ALTER TABLE serial_number_transfer_items ADD COLUMN {col_name} {col_def}")
                        logger.info(f"‚úÖ Added missing column: serial_number_transfer_items.{col_name} - CRITICAL FOR QUANTITY VALIDATION")
                    except Exception as e:
                        logger.warning(f"‚ö†Ô∏è Could not add column serial_number_transfer_items.{col_name}: {e}")

        self.connection.commit()
        logger.info("‚úÖ Column migration completed - QR Code generation, Sales Order integration, Serial Transfer quantity validation, and SAP B1 inventory transfer enhancements updated!")
    
    def create_all_tables(self):
        """Create all WMS tables in correct order (dependencies first)"""
        
        # 1. Users table (no dependencies)
        if not self.table_exists('users'):
            logger.info("Creating users table...")
            self.execute_query("""
                CREATE TABLE users (
                    id INT AUTO_INCREMENT PRIMARY KEY,
                    username VARCHAR(80) UNIQUE NOT NULL,
                    email VARCHAR(120) UNIQUE NOT NULL,
                    password_hash VARCHAR(256) NOT NULL,
                    first_name VARCHAR(80),
                    last_name VARCHAR(80),
                    role VARCHAR(20) NOT NULL DEFAULT 'user',
                    branch_id VARCHAR(10),
                    branch_name VARCHAR(100),
                    default_branch_id VARCHAR(10),
                    is_active BOOLEAN DEFAULT TRUE,
                    must_change_password BOOLEAN DEFAULT FALSE,
                    last_login DATETIME,
                    permissions TEXT,
                    created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                    updated_at DATETIME DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
                    INDEX idx_username (username),
                    INDEX idx_role (role),
                    INDEX idx_branch (branch_id)
                ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci
            """)
            logger.info("‚úÖ Users table created")
        
        # 2. Branches table (no dependencies) 
        if not self.table_exists('branches'):
            logger.info("Creating branches table...")
            self.execute_query("""
                CREATE TABLE branches (
                    id VARCHAR(10) PRIMARY KEY,
                    name VARCHAR(100),
                    description VARCHAR(255),
                    address VARCHAR(255),
                    phone VARCHAR(20),
                    email VARCHAR(120),
                    manager_name VARCHAR(100),
                    is_active BOOLEAN DEFAULT TRUE,
                    is_default BOOLEAN DEFAULT FALSE,
                    branch_code VARCHAR(10) NOT NULL,
                    branch_name VARCHAR(100) NOT NULL,
                    city VARCHAR(50),
                    state VARCHAR(50),
                    postal_code VARCHAR(20),
                    country VARCHAR(50),
                    warehouse_codes TEXT,
                    created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                    updated_at DATETIME DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
                    INDEX idx_branch_code (branch_code),
                    INDEX idx_active (is_active),
                    INDEX idx_id (id)
                ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci
            """)
            logger.info("‚úÖ Branches table created")
        
        # 3. GRPO Documents (depends on users) - Updated to match current models
        if not self.table_exists('grpo_documents'):
            logger.info("Creating grpo_documents table...")
            self.execute_query("""
                CREATE TABLE grpo_documents (
                    id INT AUTO_INCREMENT PRIMARY KEY,
                    po_number VARCHAR(20) NOT NULL,
                    sap_document_number VARCHAR(20),
                    supplier_code VARCHAR(50),
                    supplier_name VARCHAR(200),
                    po_date DATETIME,
                    qc_approved_at DATETIME,
                    po_total DECIMAL(15,2),
                    status VARCHAR(20) DEFAULT 'draft',
                    user_id INT NOT NULL,
                    qc_user_id INT,
                    qc_notes TEXT,
                    notes TEXT,
                    draft_or_post VARCHAR(10) DEFAULT 'draft',
                    created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                    updated_at DATETIME DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
                    FOREIGN KEY (user_id) REFERENCES users(id) ON DELETE CASCADE,
                    FOREIGN KEY (qc_user_id) REFERENCES users(id) ON DELETE SET NULL,
                    INDEX idx_po_number (po_number),
                    INDEX idx_supplier (supplier_code),
                    INDEX idx_status (status),
                    INDEX idx_sap_doc (sap_document_number)
                ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci
            """)
            logger.info("‚úÖ GRPO documents table created")
        
        # 4. GRPO Items (depends on grpo_documents) - Updated to match current models
        if not self.table_exists('grpo_items'):
            logger.info("Creating grpo_items table...")
            self.execute_query("""
                CREATE TABLE grpo_items (
                    id INT AUTO_INCREMENT PRIMARY KEY,
                    grpo_document_id INT NOT NULL,
                    po_line_number INT,
                    item_code VARCHAR(50) NOT NULL,
                    item_name VARCHAR(200) NOT NULL,
                    po_quantity DECIMAL(15,3),
                    open_quantity DECIMAL(15,3),
                    received_quantity DECIMAL(15,3) NOT NULL,
                    unit_of_measure VARCHAR(10) NOT NULL,
                    unit_price DECIMAL(15,4),
                    bin_location VARCHAR(200) NOT NULL,
                    batch_number VARCHAR(50),
                    serial_number VARCHAR(50),
                    expiration_date DATETIME,
                    supplier_barcode VARCHAR(100),
                    generated_barcode VARCHAR(100),
                    barcode_printed BOOLEAN DEFAULT FALSE,
                    qc_status VARCHAR(20) DEFAULT 'pending',
                    qc_notes TEXT,
                    created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                    FOREIGN KEY (grpo_document_id) REFERENCES grpo_documents(id) ON DELETE CASCADE,
                    INDEX idx_grpo_item (grpo_document_id),
                    INDEX idx_item_code (item_code),
                    INDEX idx_bin_location (bin_location),
                    INDEX idx_batch (batch_number),
                    INDEX idx_qc_status (qc_status)
                ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci
            """)
            logger.info("‚úÖ GRPO line items table created")
        
        # 5. Inventory Transfers (depends on users) - Updated to match current models
        if not self.table_exists('inventory_transfers'):
            logger.info("Creating inventory_transfers table...")
            self.execute_query("""
                CREATE TABLE inventory_transfers (
                    id INT AUTO_INCREMENT PRIMARY KEY,
                    transfer_request_number VARCHAR(20) NOT NULL,
                    sap_document_number VARCHAR(20),
                    status VARCHAR(20) DEFAULT 'draft',
                    user_id INT NOT NULL,
                    qc_approver_id INT,
                    qc_approved_at DATETIME,
                    qc_notes TEXT,
                    from_warehouse VARCHAR(20),
                    to_warehouse VARCHAR(20),
                    created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                    updated_at DATETIME DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
                    FOREIGN KEY (user_id) REFERENCES users(id) ON DELETE CASCADE,
                    FOREIGN KEY (qc_approver_id) REFERENCES users(id) ON DELETE SET NULL,
                    INDEX idx_transfer_number (transfer_request_number),
                    INDEX idx_warehouses (from_warehouse, to_warehouse),
                    INDEX idx_status (status),
                    INDEX idx_sap_doc (sap_document_number)
                ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci
            """)
            logger.info("‚úÖ Inventory transfer documents table created")
        
        # 6. Inventory Transfer Items (depends on inventory_transfers) - Updated to match current models
        if not self.table_exists('inventory_transfer_items'):
            logger.info("Creating inventory_transfer_items table...")
            self.execute_query("""
                CREATE TABLE inventory_transfer_items (
                    id INT AUTO_INCREMENT PRIMARY KEY,
                    inventory_transfer_id INT NOT NULL,
                    item_code VARCHAR(50) NOT NULL,
                    item_name VARCHAR(200) NOT NULL,
                    quantity DECIMAL(15,3) NOT NULL,
                    requested_quantity DECIMAL(15,3) NOT NULL,
                    transferred_quantity DECIMAL(15,3) DEFAULT 0,
                    remaining_quantity DECIMAL(15,3) NOT NULL,
                    unit_of_measure VARCHAR(10) NOT NULL,
                    from_bin VARCHAR(20),
                    to_bin VARCHAR(20),
                    from_bin_location VARCHAR(150),
                    to_bin_location VARCHAR(150),
                    batch_number VARCHAR(50),
                    available_batches TEXT,
                    qc_status VARCHAR(20) DEFAULT 'pending',
                    qc_notes TEXT,
                    created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                    FOREIGN KEY (inventory_transfer_id) REFERENCES inventory_transfers(id) ON DELETE CASCADE,
                    INDEX idx_transfer_item (inventory_transfer_id),
                    INDEX idx_item_code (item_code),
                    INDEX idx_bins (from_bin_location, to_bin_location),
                    INDEX idx_batch (batch_number),
                    INDEX idx_qc_status (qc_status)
                ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci
            """)
            logger.info("‚úÖ Inventory transfer line items table created")
        
        # 7. Pick Lists (depends on users) - Updated to match current models
        if not self.table_exists('pick_lists'):
            logger.info("Creating pick_lists table...")
            self.execute_query("""
                CREATE TABLE pick_lists (
                    id INT AUTO_INCREMENT PRIMARY KEY,
                    absolute_entry INT,
                    name VARCHAR(50) NOT NULL,
                    owner_code INT,
                    owner_name VARCHAR(100),
                    pick_date DATETIME,
                    remarks TEXT,
                    status VARCHAR(20) DEFAULT 'pending',
                    object_type VARCHAR(10) DEFAULT '156',
                    use_base_units VARCHAR(5) DEFAULT 'tNO',
                    sales_order_number VARCHAR(20),
                    pick_list_number VARCHAR(20),
                    user_id INT NOT NULL,
                    approver_id INT,
                    priority VARCHAR(10) DEFAULT 'normal',
                    warehouse_code VARCHAR(10),
                    customer_code VARCHAR(20),
                    customer_name VARCHAR(100),
                    total_items INT DEFAULT 0,
                    picked_items INT DEFAULT 0,
                    notes TEXT,
                    created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                    updated_at DATETIME DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
                    FOREIGN KEY (user_id) REFERENCES users(id) ON DELETE CASCADE,
                    FOREIGN KEY (approver_id) REFERENCES users(id) ON DELETE SET NULL,
                    INDEX idx_absolute_entry (absolute_entry),
                    INDEX idx_name (name),
                    INDEX idx_status (status),
                    INDEX idx_priority (priority),
                    INDEX idx_customer (customer_code),
                    INDEX idx_warehouse (warehouse_code),
                    INDEX idx_pick_date (pick_date)
                ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci
            """)
            logger.info("‚úÖ Pick lists table created")
        
        # 8. Pick List Items (depends on pick_lists) - Legacy compatibility
        if not self.table_exists('pick_list_items'):
            logger.info("Creating pick_list_items table...")
            self.execute_query("""
                CREATE TABLE pick_list_items (
                    id INT AUTO_INCREMENT PRIMARY KEY,
                    pick_list_id INT NOT NULL,
                    item_code VARCHAR(50) NOT NULL,
                    item_name VARCHAR(200) NOT NULL,
                    quantity DECIMAL(15,3) NOT NULL,
                    picked_quantity DECIMAL(15,3) DEFAULT 0,
                    unit_of_measure VARCHAR(10) NOT NULL,
                    bin_location VARCHAR(120) NOT NULL,
                    batch_number VARCHAR(50),
                    created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                    FOREIGN KEY (pick_list_id) REFERENCES pick_lists(id) ON DELETE CASCADE,
                    INDEX idx_pick_list (pick_list_id),
                    INDEX idx_item_code (item_code),
                    INDEX idx_bin_location (bin_location),
                    INDEX idx_batch (batch_number)
                ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci
            """)
            logger.info("‚úÖ Pick list items table created")
        
        # 9. Pick List Lines (depends on pick_lists) - Updated to match current models
        if not self.table_exists('pick_list_lines'):
            logger.info("Creating pick_list_lines table...")
            self.execute_query("""
                CREATE TABLE pick_list_lines (
                    id INT AUTO_INCREMENT PRIMARY KEY,
                    pick_list_id INT NOT NULL,
                    absolute_entry INT,
                    line_number INT NOT NULL,
                    order_entry INT,
                    order_row_id INT,
                    picked_quantity DECIMAL(15,3) DEFAULT 0,
                    pick_status VARCHAR(20) DEFAULT 'ps_Open',
                    released_quantity DECIMAL(15,3) DEFAULT 0,
                    previously_released_quantity DECIMAL(15,3) DEFAULT 0,
                    base_object_type INT DEFAULT 17,
                    item_code VARCHAR(50),
                    item_name VARCHAR(200),
                    unit_of_measure VARCHAR(10),
                    serial_numbers TEXT,
                    batch_numbers TEXT,
                    created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                    FOREIGN KEY (pick_list_id) REFERENCES pick_lists(id) ON DELETE CASCADE,
                    INDEX idx_pick_list_line (pick_list_id, line_number),
                    INDEX idx_absolute_entry (absolute_entry),
                    INDEX idx_order_entry (order_entry, order_row_id),
                    INDEX idx_item_code (item_code),
                    INDEX idx_pick_status (pick_status)
                ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci
            """)
            logger.info("‚úÖ Pick list lines table created")
        

        # 10. Pick List Bin Allocations (depends on pick_list_lines) - Updated to match current models  
        if not self.table_exists('pick_list_bin_allocations'):
            logger.info("Creating pick_list_bin_allocations table...")
            self.execute_query("""
                CREATE TABLE pick_list_bin_allocations (
                    id INT AUTO_INCREMENT PRIMARY KEY,
                    pick_list_line_id INT NOT NULL,
                    bin_abs_entry INT,
                    quantity DECIMAL(15,3) NOT NULL,
                    allow_negative_quantity VARCHAR(5) DEFAULT 'tNO',
                    serial_and_batch_numbers_base_line INT DEFAULT 0,
                    base_line_number INT,
                    bin_code VARCHAR(20),
                    bin_location VARCHAR(150),
                    warehouse_code VARCHAR(10),
                    picked_quantity DECIMAL(15,3) DEFAULT 0,
                    created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                    FOREIGN KEY (pick_list_line_id) REFERENCES pick_list_lines(id) ON DELETE CASCADE,
                    INDEX idx_pick_list_line (pick_list_line_id),
                    INDEX idx_bin_abs_entry (bin_abs_entry),
                    INDEX idx_warehouse_bin (warehouse_code, bin_code)
                ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci
            """)
            logger.info("‚úÖ Pick list bin allocations table created")

        # 11. Inventory Counts (depends on users) - Updated to match current models
        if not self.table_exists('inventory_counts'):
            logger.info("Creating inventory_counts table...")
            self.execute_query("""
                CREATE TABLE inventory_counts (
                    id INT AUTO_INCREMENT PRIMARY KEY,
                    count_number VARCHAR(20) NOT NULL,
                    warehouse_code VARCHAR(10) NOT NULL,
                    bin_location VARCHAR(20) NOT NULL,
                    status VARCHAR(20) DEFAULT 'assigned',
                    user_id INT NOT NULL,
                    created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                    updated_at DATETIME DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
                    FOREIGN KEY (user_id) REFERENCES users(id) ON DELETE CASCADE,
                    INDEX idx_count_number (count_number),
                    INDEX idx_warehouse (warehouse_code),
                    INDEX idx_bin_location (bin_location),
                    INDEX idx_status (status)
                ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci
            """)
            logger.info("‚úÖ Inventory counts table created")

        # 12. Inventory Count Items (depends on inventory_counts)
        if not self.table_exists('inventory_count_items'):
            logger.info("Creating inventory_count_items table...")
            self.execute_query("""
                CREATE TABLE inventory_count_items (
                    id INT AUTO_INCREMENT PRIMARY KEY,
                    inventory_count_id INT NOT NULL,
                    item_code VARCHAR(50) NOT NULL,
                    item_name VARCHAR(200) NOT NULL,
                    system_quantity DECIMAL(15,3) NOT NULL,
                    counted_quantity DECIMAL(15,3) NOT NULL,
                    variance DECIMAL(15,3) NOT NULL,
                    unit_of_measure VARCHAR(10) NOT NULL,
                    batch_number VARCHAR(50),
                    created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                    FOREIGN KEY (inventory_count_id) REFERENCES inventory_counts(id) ON DELETE CASCADE,
                    INDEX idx_inventory_count (inventory_count_id),
                    INDEX idx_item_code (item_code),
                    INDEX idx_batch (batch_number)
                ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci
            """)
            logger.info("‚úÖ Inventory count items table created")

        # 13. Barcode Labels
        if not self.table_exists('barcode_labels'):
            logger.info("Creating barcode_labels table...")
            self.execute_query("""
                CREATE TABLE barcode_labels (
                    id INT AUTO_INCREMENT PRIMARY KEY,
                    item_code VARCHAR(50) NOT NULL,
                    barcode VARCHAR(100) NOT NULL,
                    label_format VARCHAR(20) NOT NULL,
                    print_count INT DEFAULT 0,
                    created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                    last_printed DATETIME,
                    INDEX idx_item_code (item_code),
                    INDEX idx_barcode (barcode)
                ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci
            """)
            logger.info("‚úÖ Barcode labels table created")

        # 14. Bin Locations
        if not self.table_exists('bin_locations'):
            logger.info("Creating bin_locations table...")
            self.execute_query("""
                CREATE TABLE bin_locations (
                    id INT AUTO_INCREMENT PRIMARY KEY,
                    bin_code VARCHAR(100) UNIQUE NOT NULL,
                    warehouse_code VARCHAR(50) NOT NULL,
                    bin_name VARCHAR(150) NOT NULL,
                    description VARCHAR(255),
                    is_active BOOLEAN DEFAULT TRUE,
                    is_system_bin BOOLEAN DEFAULT FALSE,
                    sap_abs_entry INT,
                    created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                    updated_at DATETIME DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
                    INDEX idx_bin_code (bin_code),
                    INDEX idx_warehouse (warehouse_code),
                    INDEX idx_active (is_active),
                    INDEX idx_sap_abs_entry (sap_abs_entry)
                ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci
            """)
            logger.info("‚úÖ Bin locations table created")

        # 15. Bin Items (depends on bin_locations) - Updated to match current models
        if not self.table_exists('bin_items'):
            logger.info("Creating bin_items table...")
            self.execute_query("""
                CREATE TABLE bin_items (
                    id INT AUTO_INCREMENT PRIMARY KEY,
                    bin_code VARCHAR(100) NOT NULL,
                    item_code VARCHAR(100) NOT NULL,
                    item_name VARCHAR(255),
                    batch_number VARCHAR(100),
                    quantity DECIMAL(15,3) DEFAULT 0,
                    available_quantity DECIMAL(15,3) DEFAULT 0,
                    committed_quantity DECIMAL(15,3) DEFAULT 0,
                    uom VARCHAR(20) DEFAULT 'EA',
                    expiry_date DATE,
                    manufacturing_date DATE,
                    admission_date DATE,
                    warehouse_code VARCHAR(50),
                    sap_abs_entry INT,
                    sap_system_number INT,
                    sap_doc_entry INT,
                    batch_attribute1 VARCHAR(100),
                    batch_attribute2 VARCHAR(100),
                    batch_status VARCHAR(50) DEFAULT 'bdsStatus_Released',
                    last_sap_sync DATETIME,
                    created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                    updated_at DATETIME DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
                    FOREIGN KEY (bin_code) REFERENCES bin_locations(bin_code) ON DELETE CASCADE ON UPDATE CASCADE,
                    INDEX idx_bin_code (bin_code),
                    INDEX idx_item_code (item_code),
                    INDEX idx_warehouse (warehouse_code),
                    INDEX idx_batch (batch_number),
                    INDEX idx_sap_abs_entry (sap_abs_entry)
                ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci
            """)
            logger.info("‚úÖ Bin items table created")

        # 16. Sales Orders (for picklist integration)
        if not self.table_exists('sales_orders'):
            logger.info("Creating sales_orders table...")
            self.execute_query("""
                CREATE TABLE sales_orders (
                    id INT AUTO_INCREMENT PRIMARY KEY,
                    doc_entry INT UNIQUE NOT NULL,
                    doc_num INT,
                    doc_type VARCHAR(50),
                    doc_date DATETIME,
                    doc_due_date DATETIME,
                    card_code VARCHAR(50),
                    card_name VARCHAR(200),
                    address TEXT,
                    doc_total DECIMAL(15,2),
                    doc_currency VARCHAR(10),
                    comments TEXT,
                    document_status VARCHAR(50),
                    last_sap_sync DATETIME DEFAULT CURRENT_TIMESTAMP,
                    created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                    updated_at DATETIME DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
                    INDEX idx_doc_entry (doc_entry),
                    INDEX idx_doc_num (doc_num),
                    INDEX idx_card_code (card_code),
                    INDEX idx_doc_status (document_status),
                    INDEX idx_sap_sync (last_sap_sync)
                ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci
            """)
            logger.info("‚úÖ Sales orders table created")

        # 17. Sales Order Lines (depends on sales_orders)
        if not self.table_exists('sales_order_lines'):
            logger.info("Creating sales_order_lines table...")
            self.execute_query("""
                CREATE TABLE sales_order_lines (
                    id INT AUTO_INCREMENT PRIMARY KEY,
                    sales_order_id INT NOT NULL,
                    line_num INT NOT NULL,
                    item_code VARCHAR(100),
                    item_description VARCHAR(255),
                    quantity DECIMAL(15,3),
                    open_quantity DECIMAL(15,3),
                    delivered_quantity DECIMAL(15,3),
                    unit_price DECIMAL(15,4),
                    line_total DECIMAL(15,2),
                    warehouse_code VARCHAR(50),
                    unit_of_measure VARCHAR(20),
                    line_status VARCHAR(50),
                    created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                    updated_at DATETIME DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
                    FOREIGN KEY (sales_order_id) REFERENCES sales_orders(id) ON DELETE CASCADE,
                    INDEX idx_sales_order (sales_order_id),
                    INDEX idx_line_num (line_num),
                    INDEX idx_item_code (item_code),
                    INDEX idx_warehouse (warehouse_code),
                    INDEX idx_line_status (line_status),
                    UNIQUE KEY unique_order_line (sales_order_id, line_num)
                ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci
            """)
            logger.info("‚úÖ Sales order lines table created")

        # 19. Bin Scanning Logs (depends on users and bin_locations)
        if not self.table_exists('bin_scanning_logs'):
            logger.info("Creating bin_scanning_logs table...")
            self.execute_query("""
                CREATE TABLE bin_scanning_logs (
                    id INT AUTO_INCREMENT PRIMARY KEY,
                    bin_code VARCHAR(100) NOT NULL,
                    user_id INT NULL,
                    scan_type VARCHAR(50) NOT NULL,
                    scan_data VARCHAR(150),
                    items_found INT DEFAULT 0,
                    scan_timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
                    FOREIGN KEY (user_id) REFERENCES users(id) ON DELETE CASCADE,
                    INDEX idx_bin_code (bin_code),
                    INDEX idx_user_id (user_id),
                    INDEX idx_scan_timestamp (scan_timestamp),
                    INDEX idx_scan_type (scan_type)
                ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci
            """)
            logger.info("‚úÖ Bin scanning logs table created")

        # 20. QR Code Labels (depends on users) - Updated to match current models exactly
        if not self.table_exists('qr_code_labels'):
            logger.info("Creating qr_code_labels table...")
            self.execute_query("""
                CREATE TABLE qr_code_labels (
                    id INT AUTO_INCREMENT PRIMARY KEY,
                    label_number VARCHAR(50) NULL,
                    qr_code_data TEXT NULL,
                    label_type VARCHAR(50) NOT NULL,
                    item_code VARCHAR(100) NOT NULL,
                    item_name VARCHAR(200),
                    po_number VARCHAR(100),
                    batch_number VARCHAR(100),
                    warehouse_code VARCHAR(50),
                    bin_code VARCHAR(100),
                    quantity DECIMAL(15,4),
                    uom VARCHAR(20),
                    expiry_date DATE,
                    qr_content TEXT NOT NULL,
                    qr_format VARCHAR(20) DEFAULT 'TEXT',
                    grpo_item_id INT,
                    inventory_transfer_item_id INT,
                    user_id INT NOT NULL,
                    created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                    updated_at DATETIME DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
                    FOREIGN KEY (user_id) REFERENCES users(id) ON DELETE CASCADE,
                    FOREIGN KEY (grpo_item_id) REFERENCES grpo_items(id) ON DELETE SET NULL,
                    FOREIGN KEY (inventory_transfer_item_id) REFERENCES inventory_transfer_items(id) ON DELETE SET NULL,
                    INDEX idx_label_number (label_number),
                    INDEX idx_label_type (label_type),
                    INDEX idx_item_code (item_code),
                    INDEX idx_po_number (po_number),
                    INDEX idx_batch (batch_number),
                    INDEX idx_warehouse_bin (warehouse_code, bin_code)
                ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci
            """)
            logger.info("‚úÖ QR code labels table created with label_number field")

        # Legacy inventory counting documents for backward compatibility  
        if not self.table_exists('inventory_counting_documents'):
            logger.info("Creating inventory_counting_documents table...")
            self.execute_query("""
                CREATE TABLE inventory_counting_documents (
                    id INT AUTO_INCREMENT PRIMARY KEY,
                    counting_number VARCHAR(50) UNIQUE NOT NULL,
                    counting_date DATE,
                    warehouse_code VARCHAR(10),
                    counting_type VARCHAR(20) DEFAULT 'full',
                    status VARCHAR(20) DEFAULT 'open',
                    total_items INT DEFAULT 0,
                    counted_items INT DEFAULT 0,
                    variance_items INT DEFAULT 0,
                    user_id INT,
                    approved_by_id INT,
                    approved_at DATETIME,
                    posted_at DATETIME,
                    sap_doc_entry INT,
                    sap_doc_num VARCHAR(20),
                    remarks TEXT,
                    created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                    updated_at DATETIME DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
                    FOREIGN KEY (user_id) REFERENCES users(id) ON DELETE SET NULL,
                    FOREIGN KEY (approved_by_id) REFERENCES users(id) ON DELETE SET NULL,
                    INDEX idx_counting_number (counting_number),
                    INDEX idx_warehouse (warehouse_code),
                    INDEX idx_status (status),
                    INDEX idx_counting_date (counting_date),
                    INDEX idx_sap_doc (sap_doc_entry)
                ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci
            """)
            logger.info("‚úÖ Inventory counting documents table created")
        
        # 11. Inventory Counting Line Items (depends on inventory_counting_documents)
        if not self.table_exists('inventory_counting_line_items'):
            logger.info("Creating inventory_counting_line_items table...")
            self.execute_query("""
                CREATE TABLE inventory_counting_line_items (
                    id INT AUTO_INCREMENT PRIMARY KEY,
                    counting_id INT NOT NULL,
                    line_number INT NOT NULL,
                    item_code VARCHAR(50),
                    item_description TEXT,
                    warehouse_code VARCHAR(10),
                    bin_location VARCHAR(150),
                    batch_number VARCHAR(50),
                    serial_numbers TEXT,
                    system_quantity DECIMAL(15,3),
                    counted_quantity DECIMAL(15,3),
                    variance_quantity DECIMAL(15,3),
                    unit_cost DECIMAL(15,4),
                    variance_value DECIMAL(15,2),
                    counting_date DATE,
                    counter_user_id INT,
                    remarks TEXT,
                    sap_line_num INT,
                    created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                    updated_at DATETIME DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
                    FOREIGN KEY (counting_id) REFERENCES inventory_counting_documents(id) ON DELETE CASCADE,
                    FOREIGN KEY (counter_user_id) REFERENCES users(id) ON DELETE SET NULL,
                    INDEX idx_counting_line (counting_id, line_number),
                    INDEX idx_item_code (item_code),
                    INDEX idx_warehouse_bin (warehouse_code, bin_location),
                    INDEX idx_batch (batch_number),
                    INDEX idx_variance (variance_quantity)
                ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci
            """)
            logger.info("‚úÖ Inventory counting line items table created")
        
        # 12. Bin Scanning Logs (depends on users)
        if not self.table_exists('bin_scanning_logs'):
            logger.info("Creating bin_scanning_logs table...")
            self.execute_query("""
                CREATE TABLE bin_scanning_logs (
                    id INT AUTO_INCREMENT PRIMARY KEY,
                    bin_code VARCHAR(50) NOT NULL,
                    warehouse_code VARCHAR(10),
                    scan_type VARCHAR(20) DEFAULT 'inquiry',
                    scanned_by_id INT,
                    scan_timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
                    items_found INT DEFAULT 0,
                    scan_result TEXT,
                    device_info VARCHAR(100),
                    session_id VARCHAR(50),
                    created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                    FOREIGN KEY (scanned_by_id) REFERENCES users(id) ON DELETE SET NULL,
                    INDEX idx_bin_code (bin_code),
                    INDEX idx_warehouse (warehouse_code),
                    INDEX idx_scan_timestamp (scan_timestamp),
                    INDEX idx_scanned_by (scanned_by_id),
                    INDEX idx_session (session_id)
                ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci
            """)
            logger.info("‚úÖ Bin scanning logs table created")
        
        # 13. QR Code Labels (depends on users)
        if not self.table_exists('qr_code_labels'):
            logger.info("Creating qr_code_labels table...")
            self.execute_query("""
                CREATE TABLE qr_code_labels (
                    id INT AUTO_INCREMENT PRIMARY KEY,
                    label_number VARCHAR(50) UNIQUE NOT NULL,
                    qr_code_data TEXT NOT NULL,
                    label_type VARCHAR(20) DEFAULT 'item',
                    item_code VARCHAR(50),
                    item_description TEXT,
                    batch_number VARCHAR(50),
                    serial_number VARCHAR(50),
                    warehouse_code VARCHAR(10),
                    bin_location VARCHAR(150),
                    quantity DECIMAL(15,3),
                    unit_of_measure VARCHAR(20),
                    expiry_date DATE,
                    manufacturing_date DATE,
                    print_count INT DEFAULT 0,
                    last_printed_at DATETIME,
                    created_by_id INT,
                    status VARCHAR(20) DEFAULT 'active',
                    created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                    updated_at DATETIME DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
                    FOREIGN KEY (created_by_id) REFERENCES users(id) ON DELETE SET NULL,
                    INDEX idx_label_number (label_number),
                    INDEX idx_item_code (item_code),
                    INDEX idx_batch_serial (batch_number, serial_number),
                    INDEX idx_warehouse_bin (warehouse_code, bin_location),
                    INDEX idx_label_type (label_type),
                    INDEX idx_status (status)
                ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci
            """)
            logger.info("‚úÖ QR code labels table created")
        
        # 14. Serial Number Transfer Documents (depends on users) - NEW
        if not self.table_exists('serial_number_transfers'):
            logger.info("Creating serial_number_transfers table...")
            self.execute_query("""
                CREATE TABLE serial_number_transfers (
                    id INT AUTO_INCREMENT PRIMARY KEY,
                    transfer_number VARCHAR(50) NOT NULL UNIQUE,
                    sap_document_number VARCHAR(50),
                    status VARCHAR(20) DEFAULT 'draft',
                    user_id INT NOT NULL,
                    qc_approver_id INT,
                    qc_approved_at DATETIME,
                    qc_notes TEXT,
                    from_warehouse VARCHAR(10) NOT NULL,
                    to_warehouse VARCHAR(10) NOT NULL,
                    priority VARCHAR(10) DEFAULT 'normal',
                    notes TEXT,
                    created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                    updated_at DATETIME DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
                    FOREIGN KEY (user_id) REFERENCES users(id) ON DELETE CASCADE,
                    FOREIGN KEY (qc_approver_id) REFERENCES users(id) ON DELETE SET NULL,
                    INDEX idx_transfer_number (transfer_number),
                    INDEX idx_status (status),
                    INDEX idx_user (user_id),
                    INDEX idx_warehouses (from_warehouse, to_warehouse),
                    INDEX idx_created_at (created_at)
                ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci
            """)
            logger.info("‚úÖ Serial number transfers table created")
        
        # 15. Serial Number Transfer Items (depends on serial_number_transfers) - NEW
        if not self.table_exists('serial_number_transfer_items'):
            logger.info("Creating serial_number_transfer_items table...")
            self.execute_query("""
                CREATE TABLE serial_number_transfer_items (
                    id INT AUTO_INCREMENT PRIMARY KEY,
                    serial_transfer_id INT NOT NULL,
                    item_code VARCHAR(50) NOT NULL,
                    item_name VARCHAR(200),
                    quantity INT NOT NULL,
                    unit_of_measure VARCHAR(10) DEFAULT 'EA',
                    from_warehouse_code VARCHAR(10) NOT NULL,
                    to_warehouse_code VARCHAR(10) NOT NULL,
                    qc_status VARCHAR(20) DEFAULT 'pending',
                    created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                    updated_at DATETIME DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
                    FOREIGN KEY (serial_transfer_id) REFERENCES serial_number_transfers(id) ON DELETE CASCADE,
                    INDEX idx_serial_transfer (serial_transfer_id),
                    INDEX idx_item_code (item_code),
                    INDEX idx_warehouses (from_warehouse_code, to_warehouse_code),
                    INDEX idx_qc_status (qc_status)
                ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci
            """)
            logger.info("‚úÖ Serial number transfer items table created")
        
        # 16. Serial Number Transfer Serials (depends on serial_number_transfer_items) - NEW
        if not self.table_exists('serial_number_transfer_serials'):
            logger.info("Creating serial_number_transfer_serials table...")
            self.execute_query("""
                CREATE TABLE serial_number_transfer_serials (
                    id INT AUTO_INCREMENT PRIMARY KEY,
                    transfer_item_id INT NOT NULL,
                    serial_number VARCHAR(100) NOT NULL,
                    internal_serial_number VARCHAR(100) NOT NULL,
                    system_serial_number INT,
                    is_validated BOOLEAN DEFAULT FALSE,
                    validation_error TEXT,
                    manufacturing_date DATE,
                    expiry_date DATE,
                    admission_date DATE,
                    created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                    FOREIGN KEY (transfer_item_id) REFERENCES serial_number_transfer_items(id) ON DELETE CASCADE,
                    UNIQUE KEY unique_serial_per_item (transfer_item_id, serial_number),
                    INDEX idx_transfer_item (transfer_item_id),
                    INDEX idx_serial_number (serial_number),
                    INDEX idx_is_validated (is_validated),
                    INDEX idx_system_serial (system_serial_number)
                ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci
            """)
            logger.info("‚úÖ Serial number transfer serials table created")
        
        self.connection.commit()
        logger.info("‚úÖ All tables created successfully!")
        return True
    
    def insert_default_data(self):
        """Insert default admin user and sample data"""
        
        # Check if admin user already exists
        admin_exists = self.execute_query("SELECT COUNT(*) as count FROM users WHERE username = 'admin'")
        if admin_exists[0]['count'] > 0:
            logger.info("Admin user already exists, skipping default data insertion")
            return True
        
        logger.info("Inserting default data...")
        
        # Default admin user
        admin_password_hash = generate_password_hash('admin123')
        self.execute_query("""
            INSERT INTO users (
                username, email, password_hash, first_name, last_name, 
                role, branch_id, branch_name, permissions
            ) VALUES (
                'admin', 'admin@company.com', %s, 'System', 'Administrator',
                'admin', '01', 'Main Branch', 'all'
            )
        """, [admin_password_hash])
        
        # Default manager user
        manager_password_hash = generate_password_hash('manager123')
        self.execute_query("""
            INSERT INTO users (
                username, email, password_hash, first_name, last_name,
                role, branch_id, branch_name, permissions
            ) VALUES (
                'manager', 'manager@company.com', %s, 'Warehouse', 'Manager',
                'manager', '01', 'Main Branch', 'grpo,inventory_transfer,pick_list,inventory_counting,bin_scanning'
            )
        """, [manager_password_hash])
        
        # Default user
        user_password_hash = generate_password_hash('user123')
        self.execute_query("""
            INSERT INTO users (
                username, email, password_hash, first_name, last_name,
                role, branch_id, branch_name, permissions
            ) VALUES (
                'user', 'user@company.com', %s, 'Warehouse', 'User',
                'user', '01', 'Main Branch', 'grpo,inventory_transfer,pick_list,bin_scanning'
            )
        """, [user_password_hash])
        
        # Default QC user
        qc_password_hash = generate_password_hash('qc123')
        self.execute_query("""
            INSERT INTO users (
                username, email, password_hash, first_name, last_name,
                role, branch_id, branch_name, permissions
            ) VALUES (
                'qc', 'qc@company.com', %s, 'Quality', 'Control',
                'qc', '01', 'Main Branch', 'grpo,inventory_counting,qc_dashboard'
            )
        """, [qc_password_hash])
        
        # Default branch
        self.execute_query("""
            INSERT INTO branches (
                id, name, description, branch_code, branch_name, address, city, state, country,
                phone, email, manager_name, warehouse_codes, is_active, is_default
            ) VALUES (
                'BR001', 'Main Branch', 'Primary warehouse branch', '01', 'Main Branch', 
                '123 Warehouse St', 'Business City', 'State', 'Country',
                '+1-555-0123', 'main@company.com', 'Warehouse Manager', '01,02,03',
                TRUE, TRUE
            )
        """)
        
        self.connection.commit()
        logger.info("‚úÖ Default data inserted successfully!")
        logger.info("")
        logger.info("=== DEFAULT USER ACCOUNTS ===")
        logger.info("Admin:   username='admin'   password='admin123'")
        logger.info("Manager: username='manager' password='manager123'")
        logger.info("User:    username='user'    password='user123'")
        logger.info("QC:      username='qc'      password='qc123'")
        logger.info("")
        return True
    
    def remove_duplicate_migration_files(self):
        """Remove duplicate MySQL migration files"""
        duplicate_files = [
            'mysql_migration.py',
            'mysql_complete_migration.py', 
            'mysql_picklist_migration.py',
            'mysql_qr_code_migration.py',
            'mysql_complete_picklist_migration_august_2025.py',
            'run_mysql_picklist_migration.py',
            'complete_mysql_fix.py',
            'fix_mysql_schema.py',
            'setup_mysql_env.py',
            'sync_mysql_changes.py',
            'qr_code_migration.py',
            'fix_picklist_schema.py'
        ]
        
        removed_count = 0
        for file_name in duplicate_files:
            if os.path.exists(file_name):
                try:
                    os.remove(file_name)
                    logger.info(f"‚úÖ Removed duplicate migration file: {file_name}")
                    removed_count += 1
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è Could not remove {file_name}: {e}")
        
        if removed_count > 0:
            logger.info(f"‚úÖ Removed {removed_count} duplicate migration files")
        else:
            logger.info("No duplicate migration files found to remove")
        
        return True
    
    def run_migration(self):
        """Run complete migration process"""
        logger.info("=== WMS Complete MySQL Migration - FINAL VERSION ===")
        logger.info("This script consolidates ALL WMS modules into one database")
        logger.info("")
        
        # Get MySQL configuration
        config = self.get_mysql_config()
        
        # Connect to MySQL
        if not self.connect(config):
            return False
        
        try:
            # Create .env file
            if not self.create_env_file(config):
                return False
            
            # Add missing columns to existing tables first
            self.add_missing_columns()
            
            # Create all tables
            if not self.create_all_tables():
                return False
            
            # Insert default data
            if not self.insert_default_data():
                return False
            
            # Clean up duplicate files
            self.remove_duplicate_migration_files()
            
            logger.info("")
            logger.info("üéâ MIGRATION COMPLETED SUCCESSFULLY! üéâ")
            logger.info("")
            logger.info("Next steps:")
            logger.info("1. Update your application to use the new .env file")
            logger.info("2. Start your Flask application: python main.py")
            logger.info("3. Login with admin/admin123 to begin using WMS")
            logger.info("4. Configure SAP B1 settings in .env file if needed")
            logger.info("")
            logger.info("All duplicate migration files have been removed.")
            logger.info("This file (mysql_complete_migration_final.py) is now your single migration script.")
            
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Migration failed: {e}")
            return False
        
        finally:
            if self.connection:
                self.connection.close()
                logger.info("MySQL connection closed")

if __name__ == "__main__":
    migration = CompleteMySQLMigrationFinal()
    success = migration.run_migration()
    sys.exit(0 if success else 1)